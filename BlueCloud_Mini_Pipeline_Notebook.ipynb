{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🌊🦈 BlueCloud Mini Pipeline - Interactive Analysis\n",
        "\n",
        "This notebook provides an interactive version of the BlueCloud Mini Pipeline, allowing you to explore skate tracking data, plankton distributions, and elasmobranch capture data with comprehensive visualizations and machine learning models.\n",
        "\n",
        "## 📋 Table of Contents\n",
        "1. [Setup and Configuration](#setup)\n",
        "2. [Data Processing](#data-processing)\n",
        "   - [Skate Data Processing](#skate-data)\n",
        "   - [Plankton Data Processing](#plankton-data)\n",
        "   - [Elasmobranch Data Processing](#elasmobranch-data)\n",
        "3. [Machine Learning Model](#ml-model)\n",
        "4. [Visualizations](#visualizations)\n",
        "5. [Results and Analysis](#results)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Setup and Configuration {#setup}\n",
        "\n",
        "First, let's set up the environment and configure the pipeline parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌊🦈 BlueCloud Mini Pipeline - Interactive Analysis\n",
            "==================================================\n",
            "📅 Started at: 2025-10-01 10:13:46\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the pipeline modules to path\n",
        "current_dir = os.getcwd()\n",
        "if 'deliverable4' not in current_dir:\n",
        "    os.chdir('/home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4')\n",
        "\n",
        "from pipeline.main_pipeline import MainPipeline\n",
        "from modules import (\n",
        "    SkateProcessor,\n",
        "    PlanktonProcessor,\n",
        "    ElasmobranchProcessor,\n",
        "    TinyModel,\n",
        "    Visualizer\n",
        ")\n",
        "\n",
        "print(\"🌊🦈 BlueCloud Mini Pipeline - Interactive Analysis\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"📅 Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuration Parameters\n",
        "\n",
        "Configure the pipeline with your data paths and parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📋 Configuration:\n",
            "  ✅ skate_csv_path: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/Skates_Track.csv\n",
            "  ✅ plankton_netcdf_dir: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/planktonoutputs\n",
            "  📊 use_sample_plankton: True\n",
            "  ✅ output_dir: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data\n",
            "  ⚠️  model_type: random_forest (file not found)\n",
            "  📊 random_state: 42\n",
            "  📊 test_size: 0.2\n",
            "  ✅ capture_csv_path: /home/samwork/Documents/coding/bluecloud-hackathon-2025/Capture_2025.1.0/Capture_Quantity.csv\n",
            "  ✅ species_metadata_path: /home/samwork/Documents/coding/bluecloud-hackathon-2025/Capture_2025.1.0/CL_FI_SPECIES_GROUPS.csv\n",
            "  ✅ water_area_path: /home/samwork/Documents/coding/bluecloud-hackathon-2025/Capture_2025.1.0/CL_FI_WATERAREA_GROUPS.csv\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "base_dir = os.getcwd()\n",
        "project_root = os.path.dirname(base_dir)\n",
        "\n",
        "config = {\n",
        "    'skate_csv_path': os.path.join(base_dir, 'data/Skates_Track.csv'),\n",
        "    'plankton_netcdf_dir': os.path.join(base_dir, 'data/planktonoutputs'),\n",
        "    'use_sample_plankton': True,  # Set to False when you have real NetCDF files\n",
        "    'output_dir': os.path.join(base_dir, 'data'),\n",
        "    'model_type': 'random_forest',  # Options: 'random_forest', 'linear_regression', 'gradient_boosting'\n",
        "    'random_state': 42,\n",
        "    'test_size': 0.2,\n",
        "    # Elasmobranch data paths\n",
        "    'capture_csv_path': os.path.join(project_root, 'Capture_2025.1.0', 'Capture_Quantity.csv'),\n",
        "    'species_metadata_path': os.path.join(project_root, 'Capture_2025.1.0', 'CL_FI_SPECIES_GROUPS.csv'),\n",
        "    'water_area_path': os.path.join(project_root, 'Capture_2025.1.0', 'CL_FI_WATERAREA_GROUPS.csv')\n",
        "}\n",
        "\n",
        "print(\"📋 Configuration:\")\n",
        "for key, value in config.items():\n",
        "    if isinstance(value, str) and os.path.exists(value):\n",
        "        print(f\"  ✅ {key}: {value}\")\n",
        "    elif isinstance(value, str):\n",
        "        print(f\"  ⚠️  {key}: {value} (file not found)\")\n",
        "    else:\n",
        "        print(f\"  📊 {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Validation\n",
        "\n",
        "Let's check if all required data files are available:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Validating input files...\n",
            "------------------------------\n",
            "✅ Skate data found: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/Skates_Track.csv\n",
            "   📊 Records: 4,925\n",
            "   📅 Date range: 2021-08-05 to 2024-08-20\n",
            "⚠️  Plankton directory exists but no .nc files found\n",
            "   Will use sample plankton data\n",
            "✅ All elasmobranch data files found\n",
            "\n",
            "📁 Output directory: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data\n"
          ]
        }
      ],
      "source": [
        "# Validate input files\n",
        "print(\"🔍 Validating input files...\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Check skate data\n",
        "if os.path.exists(config['skate_csv_path']):\n",
        "    print(f\"✅ Skate data found: {config['skate_csv_path']}\")\n",
        "    skate_df = pd.read_csv(config['skate_csv_path'])\n",
        "    print(f\"   📊 Records: {len(skate_df):,}\")\n",
        "    print(f\"   📅 Date range: {skate_df['Date'].min()} to {skate_df['Date'].max()}\")\n",
        "else:\n",
        "    print(f\"❌ Skate data not found: {config['skate_csv_path']}\")\n",
        "\n",
        "# Check plankton data\n",
        "if os.path.exists(config['plankton_netcdf_dir']):\n",
        "    netcdf_files = [f for f in os.listdir(config['plankton_netcdf_dir']) if f.endswith('.nc')]\n",
        "    if netcdf_files:\n",
        "        print(f\"✅ Plankton NetCDF files found: {len(netcdf_files)} files\")\n",
        "        config['use_sample_plankton'] = False\n",
        "    else:\n",
        "        print(f\"⚠️  Plankton directory exists but no .nc files found\")\n",
        "        print(f\"   Will use sample plankton data\")\n",
        "else:\n",
        "    print(f\"⚠️  Plankton directory not found: {config['plankton_netcdf_dir']}\")\n",
        "    print(f\"   Will use sample plankton data\")\n",
        "\n",
        "# Check elasmobranch data\n",
        "capture_files = [\n",
        "    config['capture_csv_path'],\n",
        "    config['species_metadata_path'],\n",
        "    config['water_area_path']\n",
        "]\n",
        "\n",
        "missing_files = [f for f in capture_files if not os.path.exists(f)]\n",
        "if missing_files:\n",
        "    print(f\"⚠️  Missing elasmobranch files: {len(missing_files)} files\")\n",
        "    for f in missing_files:\n",
        "        print(f\"   - {os.path.basename(f)}\")\n",
        "else:\n",
        "    print(f\"✅ All elasmobranch data files found\")\n",
        "\n",
        "print(f\"\\n📁 Output directory: {config['output_dir']}\")\n",
        "os.makedirs(config['output_dir'], exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 📊 Data Processing {#data-processing}\n",
        "\n",
        "Now let's process each dataset step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🦈 Skate Data Processing {#skate-data}\n",
        "\n",
        "Process the skate tracking data to extract movement patterns and statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦈 Processing Skate Data\n",
            "==============================\n",
            "🦈🌊 Starting Skate Data Processing\n",
            "========================================\n",
            "🦈 Loading skate tracking data...\n",
            "✅ Loaded 4,925 skate tracking records\n",
            "📊 Data spans from 2021-08-05 to 2024-08-20\n",
            "🦈 Tracking 52 individual skates\n",
            "📅 Adding temporal features...\n",
            "✅ Temporal features added\n",
            "🏃‍♂️ Calculating movement metrics...\n",
            "✅ Movement metrics calculated\n",
            "🗺️ Adding spatial features...\n",
            "✅ Spatial features added\n",
            "🧹 Filtering and cleaning data...\n",
            "✅ Cleaned data: removed 52 records (1.1%)\n",
            "📊 Final dataset: 4,873 records\n",
            "📈 Calculating summary statistics...\n",
            "✅ Summary statistics calculated\n",
            "\n",
            "🎯 Skate Processing Summary:\n",
            "  📊 Total records: 4,873\n",
            "  🦈 Individual skates: 52\n",
            "  📅 Date range: 2021-08-05 to 2024-08-20\n",
            "  🏃‍♂️ Total distance: 388.20 degrees\n",
            "  ⚡ Average speed: 0.0797 degrees/day\n",
            "\n",
            "📊 Skate Data Summary:\n",
            "  Total Records: 4,925\n",
            "  Individual Skates: 52\n",
            "  Date Range: 2021-08-05 to 2024-08-20\n",
            "  Total Distance: 388.20 degrees\n",
            "  Average Speed: 0.0797 degrees/day\n",
            "💾 Exported processed data to: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/skate_processed.csv\n",
            "\n",
            "💾 Exported processed skate data to: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/skate_processed.csv\n",
            "\n",
            "📋 First 5 rows of processed skate data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Common_name</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>week</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>...</th>\n",
              "      <th>distance</th>\n",
              "      <th>time_diff</th>\n",
              "      <th>speed</th>\n",
              "      <th>direction</th>\n",
              "      <th>cumulative_distance</th>\n",
              "      <th>center_lat</th>\n",
              "      <th>center_lon</th>\n",
              "      <th>dist_from_center</th>\n",
              "      <th>lat_bin</th>\n",
              "      <th>lon_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A16746</td>\n",
              "      <td>2021-08-06</td>\n",
              "      <td>Spotted Skate</td>\n",
              "      <td>52.040958</td>\n",
              "      <td>3.280237</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>218</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061733</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.061733</td>\n",
              "      <td>-144.374741</td>\n",
              "      <td>0.061733</td>\n",
              "      <td>52.384421</td>\n",
              "      <td>1.546</td>\n",
              "      <td>1.767921</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A16746</td>\n",
              "      <td>2021-08-07</td>\n",
              "      <td>Spotted Skate</td>\n",
              "      <td>52.071792</td>\n",
              "      <td>3.182861</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>219</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102141</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.102141</td>\n",
              "      <td>-72.429850</td>\n",
              "      <td>0.163875</td>\n",
              "      <td>52.384421</td>\n",
              "      <td>1.546</td>\n",
              "      <td>1.666448</td>\n",
              "      <td>52.1</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A16746</td>\n",
              "      <td>2021-08-08</td>\n",
              "      <td>Spotted Skate</td>\n",
              "      <td>52.119983</td>\n",
              "      <td>3.070554</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>220</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>-66.775917</td>\n",
              "      <td>0.286084</td>\n",
              "      <td>52.384421</td>\n",
              "      <td>1.546</td>\n",
              "      <td>1.547318</td>\n",
              "      <td>52.1</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A16746</td>\n",
              "      <td>2021-08-09</td>\n",
              "      <td>Spotted Skate</td>\n",
              "      <td>52.146748</td>\n",
              "      <td>3.001152</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>221</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074385</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074385</td>\n",
              "      <td>-68.910433</td>\n",
              "      <td>0.360469</td>\n",
              "      <td>52.384421</td>\n",
              "      <td>1.546</td>\n",
              "      <td>1.474434</td>\n",
              "      <td>52.1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A16746</td>\n",
              "      <td>2021-08-10</td>\n",
              "      <td>Spotted Skate</td>\n",
              "      <td>52.166211</td>\n",
              "      <td>2.945024</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>222</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059407</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.059407</td>\n",
              "      <td>-70.875037</td>\n",
              "      <td>0.419875</td>\n",
              "      <td>52.384421</td>\n",
              "      <td>1.546</td>\n",
              "      <td>1.415939</td>\n",
              "      <td>52.2</td>\n",
              "      <td>2.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id       Date    Common_name   Latitude  Longitude  year  month  \\\n",
              "1  A16746 2021-08-06  Spotted Skate  52.040958   3.280237  2021      8   \n",
              "2  A16746 2021-08-07  Spotted Skate  52.071792   3.182861  2021      8   \n",
              "3  A16746 2021-08-08  Spotted Skate  52.119983   3.070554  2021      8   \n",
              "4  A16746 2021-08-09  Spotted Skate  52.146748   3.001152  2021      8   \n",
              "5  A16746 2021-08-10  Spotted Skate  52.166211   2.945024  2021      8   \n",
              "\n",
              "   day_of_year  week  day_of_week  ...  distance time_diff     speed  \\\n",
              "1          218    31            4  ...  0.061733       1.0  0.061733   \n",
              "2          219    31            5  ...  0.102141       1.0  0.102141   \n",
              "3          220    31            6  ...  0.122210       1.0  0.122210   \n",
              "4          221    32            0  ...  0.074385       1.0  0.074385   \n",
              "5          222    32            1  ...  0.059407       1.0  0.059407   \n",
              "\n",
              "    direction  cumulative_distance  center_lat  center_lon  dist_from_center  \\\n",
              "1 -144.374741             0.061733   52.384421       1.546          1.767921   \n",
              "2  -72.429850             0.163875   52.384421       1.546          1.666448   \n",
              "3  -66.775917             0.286084   52.384421       1.546          1.547318   \n",
              "4  -68.910433             0.360469   52.384421       1.546          1.474434   \n",
              "5  -70.875037             0.419875   52.384421       1.546          1.415939   \n",
              "\n",
              "   lat_bin  lon_bin  \n",
              "1     52.0      3.3  \n",
              "2     52.1      3.2  \n",
              "3     52.1      3.1  \n",
              "4     52.1      3.0  \n",
              "5     52.2      2.9  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"🦈 Processing Skate Data\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Initialize skate processor\n",
        "skate_processor = SkateProcessor(config['skate_csv_path'])\n",
        "\n",
        "# Process the data\n",
        "skate_data = skate_processor.process()\n",
        "\n",
        "# Display summary statistics\n",
        "skate_stats = skate_processor.get_summary()\n",
        "print(f\"\\n📊 Skate Data Summary:\")\n",
        "print(f\"  Total Records: {skate_stats['stats']['total_records']:,}\")\n",
        "print(f\"  Individual Skates: {skate_stats['stats']['unique_skates']}\")\n",
        "print(f\"  Date Range: {skate_stats['stats']['date_range'][0].strftime('%Y-%m-%d')} to {skate_stats['stats']['date_range'][1].strftime('%Y-%m-%d')}\")\n",
        "print(f\"  Total Distance: {skate_stats['stats']['total_distance']:.2f} degrees\")\n",
        "print(f\"  Average Speed: {skate_stats['stats']['avg_speed']:.4f} degrees/day\")\n",
        "\n",
        "# Export processed data\n",
        "skate_output = os.path.join(config['output_dir'], 'skate_processed.csv')\n",
        "skate_processor.export_processed_data(skate_output)\n",
        "print(f\"\\n💾 Exported processed skate data to: {skate_output}\")\n",
        "\n",
        "# Display first few rows\n",
        "print(f\"\\n📋 First 5 rows of processed skate data:\")\n",
        "display(skate_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🦐 Plankton Data Processing {#plankton-data}\n",
        "\n",
        "Process plankton distribution data from NetCDF files or use sample data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦐 Processing Plankton Data\n",
            "==============================\n",
            "🦐🌊 Starting Plankton Data Processing\n",
            "========================================\n",
            "🧪 Creating sample plankton data for testing...\n",
            "✅ Created sample data: 24,400 records\n",
            "📅 Adding temporal features...\n",
            "✅ Added temporal features using column: time\n",
            "🗺️ Adding spatial features...\n",
            "✅ Added spatial features using columns: latitude, longitude\n",
            "📈 Calculating summary statistics...\n",
            "✅ Calculated statistics for 3 plankton variables\n",
            "✅ Calculated statistics for 3 environmental variables\n",
            "\n",
            "🎯 Plankton Processing Summary:\n",
            "  📊 Total records: 24,400\n",
            "  📁 Source files: 1\n",
            "  🗺️ Spatial bounds: Lat 50.0-55.0°N, Lon 1.0-5.0°E\n",
            "  🦐 Plankton variables: 3\n",
            "  🌡️ Environmental variables: 3\n",
            "\n",
            "📊 Plankton Data Summary:\n",
            "  Total Records: 24,400\n",
            "  Source Files: 1\n",
            "  Plankton Variables: 3\n",
            "  Environmental Variables: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Exported processed data to: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/plankton_processed.csv\n",
            "\n",
            "💾 Exported processed plankton data to: /home/samwork/Documents/coding/bluecloud-hackathon-2025/deliverable4/data/plankton_processed.csv\n",
            "\n",
            "📋 First 5 rows of processed plankton data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>time</th>\n",
              "      <th>acartia_abundance</th>\n",
              "      <th>calanus_abundance</th>\n",
              "      <th>metridia_abundance</th>\n",
              "      <th>temperature</th>\n",
              "      <th>salinity</th>\n",
              "      <th>nitrate</th>\n",
              "      <th>file_source</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>season</th>\n",
              "      <th>lat_bin</th>\n",
              "      <th>lon_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-08-01</td>\n",
              "      <td>-18.018651</td>\n",
              "      <td>-301.713785</td>\n",
              "      <td>116.261543</td>\n",
              "      <td>11.381911</td>\n",
              "      <td>35.159451</td>\n",
              "      <td>0.847981</td>\n",
              "      <td>sample_data.nc</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>213</td>\n",
              "      <td>Summer</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-08-02</td>\n",
              "      <td>-2.365586</td>\n",
              "      <td>-207.552506</td>\n",
              "      <td>81.149997</td>\n",
              "      <td>11.838810</td>\n",
              "      <td>34.737415</td>\n",
              "      <td>1.013057</td>\n",
              "      <td>sample_data.nc</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>214</td>\n",
              "      <td>Summer</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-08-03</td>\n",
              "      <td>-14.748217</td>\n",
              "      <td>-78.952944</td>\n",
              "      <td>49.933873</td>\n",
              "      <td>13.162795</td>\n",
              "      <td>34.238062</td>\n",
              "      <td>0.751173</td>\n",
              "      <td>sample_data.nc</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>215</td>\n",
              "      <td>Summer</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-08-04</td>\n",
              "      <td>-14.431437</td>\n",
              "      <td>-49.748580</td>\n",
              "      <td>53.765649</td>\n",
              "      <td>11.644323</td>\n",
              "      <td>35.298860</td>\n",
              "      <td>3.610146</td>\n",
              "      <td>sample_data.nc</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>216</td>\n",
              "      <td>Summer</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>-38.473357</td>\n",
              "      <td>-5.322433</td>\n",
              "      <td>82.584861</td>\n",
              "      <td>11.601800</td>\n",
              "      <td>35.473720</td>\n",
              "      <td>0.513887</td>\n",
              "      <td>sample_data.nc</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>217</td>\n",
              "      <td>Summer</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   latitude  longitude       time  acartia_abundance  calanus_abundance  \\\n",
              "0      50.0        1.0 2021-08-01         -18.018651        -301.713785   \n",
              "1      50.0        1.0 2021-08-02          -2.365586        -207.552506   \n",
              "2      50.0        1.0 2021-08-03         -14.748217         -78.952944   \n",
              "3      50.0        1.0 2021-08-04         -14.431437         -49.748580   \n",
              "4      50.0        1.0 2021-08-05         -38.473357          -5.322433   \n",
              "\n",
              "   metridia_abundance  temperature   salinity   nitrate     file_source  year  \\\n",
              "0          116.261543    11.381911  35.159451  0.847981  sample_data.nc  2021   \n",
              "1           81.149997    11.838810  34.737415  1.013057  sample_data.nc  2021   \n",
              "2           49.933873    13.162795  34.238062  0.751173  sample_data.nc  2021   \n",
              "3           53.765649    11.644323  35.298860  3.610146  sample_data.nc  2021   \n",
              "4           82.584861    11.601800  35.473720  0.513887  sample_data.nc  2021   \n",
              "\n",
              "   month  day_of_year  season  lat_bin  lon_bin  \n",
              "0      8          213  Summer     50.0      1.0  \n",
              "1      8          214  Summer     50.0      1.0  \n",
              "2      8          215  Summer     50.0      1.0  \n",
              "3      8          216  Summer     50.0      1.0  \n",
              "4      8          217  Summer     50.0      1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"🦐 Processing Plankton Data\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Initialize plankton processor\n",
        "plankton_processor = PlanktonProcessor(\n",
        "    netcdf_dir=config['plankton_netcdf_dir'],\n",
        "    netcdf_files=config.get('plankton_netcdf_files', None)\n",
        ")\n",
        "\n",
        "# Process the data\n",
        "plankton_data = plankton_processor.process(\n",
        "    use_sample_data=config['use_sample_plankton']\n",
        ")\n",
        "\n",
        "# Display summary statistics\n",
        "if plankton_data is not None:\n",
        "    plankton_stats = plankton_processor.get_summary()\n",
        "    print(f\"\\n📊 Plankton Data Summary:\")\n",
        "    print(f\"  Total Records: {plankton_stats['stats']['total_records']:,}\")\n",
        "    print(f\"  Source Files: {plankton_stats['stats'].get('unique_files', 1)}\")\n",
        "    \n",
        "    if 'plankton_summary' in plankton_stats['stats']:\n",
        "        print(f\"  Plankton Variables: {len(plankton_stats['stats']['plankton_summary'])}\")\n",
        "    if 'environmental_summary' in plankton_stats['stats']:\n",
        "        print(f\"  Environmental Variables: {len(plankton_stats['stats']['environmental_summary'])}\")\n",
        "    \n",
        "    # Export processed data\n",
        "    plankton_output = os.path.join(config['output_dir'], 'plankton_processed.csv')\n",
        "    plankton_processor.export_processed_data(plankton_output)\n",
        "    print(f\"\\n💾 Exported processed plankton data to: {plankton_output}\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(f\"\\n📋 First 5 rows of processed plankton data:\")\n",
        "    display(plankton_data.head())\n",
        "else:\n",
        "    print(\"⚠️  No plankton data available\")\n",
        "    plankton_stats = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🦈 Elasmobranch Data Processing {#elasmobranch-data}\n",
        "\n",
        "Process elasmobranch capture data from fisheries databases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦈 Processing Elasmobranch Data\n",
            "===================================\n",
            "🦈🌊 Starting Elasmobranch Processing\n",
            "=============================================\n",
            "📊 Loading FAO datasets...\n",
            "  Loading capture quantity data...\n",
            "    Loaded 1,055,015 capture records\n",
            "  Loading species metadata...\n",
            "    Loaded 13,596 species records\n",
            "  Loading water area metadata...\n",
            "    Loaded 29 water area records\n",
            "✅ Data loading complete!\n",
            "🦈 Identifying elasmobranch species...\n",
            "  Found 1144 elasmobranch species\n",
            "  Species codes: ['SBL', 'NTC', 'BSK', 'CCT', 'THR', 'ALV', 'PTH', 'MAK', 'SMA', 'LMD']...\n",
            "🔗 Joining capture data with metadata...\n",
            "  Joined data: 102,553 elasmobranch capture records\n",
            "  Time range: 1950 - 2023\n",
            "  Total catch: 74,720,072 tonnes\n",
            "🌊 Filtering for North Sea region...\n",
            "  North Sea elasmobranch records: 17,165\n",
            "  Time range: 1950 - 2023\n",
            "  Total catch: 6,237,310 tonnes\n",
            "  Top elasmobranch species in North Sea:\n",
            "    Rays and skates NEI: 1,852,820 tonnes\n",
            "    Picked dogfish: 1,773,612 tonnes\n",
            "    Sharks, rays, skates, etc. NEI: 362,406 tonnes\n",
            "    Blue shark: 324,222 tonnes\n",
            "    Various sharks NEI: 304,769 tonnes\n",
            "    Small-spotted catshark: 279,452 tonnes\n",
            "    Basking shark: 255,196 tonnes\n",
            "    Cuckoo ray: 150,659 tonnes\n",
            "    Thornback ray: 136,212 tonnes\n",
            "    Dogfish sharks NEI: 129,881 tonnes\n",
            "🗺️ Creating coarse raster grid (resolution: 1.0°)...\n",
            "  Focusing on FAO area 27: 0 records\n",
            "  Grid size: 181 x 361\n",
            "  Non-zero cells: 0\n",
            "  Total catch distributed: 0 tonnes\n",
            "\n",
            "🎯 Elasmobranch Processing Summary:\n",
            "  📊 Total elasmobranch records: 102,553\n",
            "  🦈 Species identified: 1144\n",
            "  🌍 Total catch: 74,720,072 tonnes\n",
            "  📅 Time range: 1950 - 2023\n",
            "  🗺️ Raster grid: (181, 361)\n",
            "  📍 Non-zero cells: 0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[32m/tmp/ipykernel_38828/3675148383.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m     elasmobranch_data = results[\u001b[33m'elasmobranch_data'\u001b[39m]\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Display summary statistics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     elasmobranch_stats = elasmobranch_processor.get_summary()\n\u001b[32m     36\u001b[39m     print(\u001b[33mf\"\\n📊 Elasmobranch Data Summary:\"\u001b[39m)\n\u001b[32m     37\u001b[39m     print(\u001b[33mf\"  Total Records: {len(elasmobranch_data):,}\"\u001b[39m)\n\u001b[32m     38\u001b[39m     print(\u001b[33mf\"  Species: {elasmobranch_stats['stats'].get('unique_species', 'N/A')}\"\u001b[39m)\n",
            "\u001b[32m~/Documents/coding/bluecloud-hackathon-2025/deliverable4/modules/elasmobranch_processor.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    380\u001b[39m         \u001b[33m\"\"\"Get processing summary\"\"\"\u001b[39m\n\u001b[32m    381\u001b[39m         \u001b[38;5;66;03m# Calculate stats if data is available\u001b[39;00m\n\u001b[32m    382\u001b[39m         stats = {}\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.elasmobranch_data \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m             stats['unique_species'] = len(\n\u001b[32m    385\u001b[39m                 self.elasmobranch_species) if self.elasmobranch_species else 0\n\u001b[32m    386\u001b[39m             stats['unique_areas'] = self.elasmobranch_data['AREA'].nunique(\n\u001b[32m    387\u001b[39m             ) if 'AREA' in self.elasmobranch_data.columns else 0\n",
            "\u001b[32m~/Documents/coding/bluecloud-hackathon-2025/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1575\u001b[39m     @final\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m         raise ValueError(\n\u001b[32m   1578\u001b[39m             \u001b[33mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[39m\n\u001b[32m   1579\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1580\u001b[39m         )\n",
            "\u001b[31mValueError\u001b[39m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ],
      "source": [
        "print(\"🦈 Processing Elasmobranch Data\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Check if capture data files exist\n",
        "capture_files = [\n",
        "    config['capture_csv_path'],\n",
        "    config['species_metadata_path'],\n",
        "    config['water_area_path']\n",
        "]\n",
        "\n",
        "missing_files = [f for f in capture_files if not os.path.exists(f)]\n",
        "if missing_files:\n",
        "    print(\"⚠️ Missing capture data files:\")\n",
        "    for f in missing_files:\n",
        "        print(f\"  - {f}\")\n",
        "    print(\"   Skipping elasmobranch processing\")\n",
        "    elasmobranch_data = None\n",
        "    elasmobranch_stats = None\n",
        "else:\n",
        "    # Initialize elasmobranch processor\n",
        "    elasmobranch_processor = ElasmobranchProcessor(\n",
        "        capture_csv_path=config['capture_csv_path'],\n",
        "        species_metadata_path=config['species_metadata_path'],\n",
        "        water_area_path=config['water_area_path']\n",
        "    )\n",
        "    \n",
        "    # Process elasmobranch data (focus on North Sea - area 27)\n",
        "    results = elasmobranch_processor.process(\n",
        "        target_area='27', resolution=1.0\n",
        "    )\n",
        "    \n",
        "    elasmobranch_data = results['elasmobranch_data']\n",
        "    \n",
        "    # Display summary statistics\n",
        "    elasmobranch_stats = elasmobranch_processor.get_summary()\n",
        "    print(f\"\\n📊 Elasmobranch Data Summary:\")\n",
        "    print(f\"  Total Records: {len(elasmobranch_data):,}\")\n",
        "    print(f\"  Species: {elasmobranch_stats['stats'].get('unique_species', 'N/A')}\")\n",
        "    print(f\"  Water Areas: {elasmobranch_stats['stats'].get('unique_areas', 'N/A')}\")\n",
        "    \n",
        "    # Export processed data\n",
        "    elasmobranch_processor.export_raster_data(config['output_dir'])\n",
        "    print(f\"\\n💾 Exported elasmobranch raster data to: {config['output_dir']}\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(f\"\\n📋 First 5 rows of processed elasmobranch data:\")\n",
        "    display(elasmobranch_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🤖 Machine Learning Model {#ml-model}\n",
        "\n",
        "Train a machine learning model to predict skate behavior based on environmental conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🤖 Training Tiny Model\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "if skate_data is None:\n",
        "    print(\"❌ Cannot train model: Skate data not available\")\n",
        "    model = None\n",
        "else:\n",
        "    # Initialize model\n",
        "    model = TinyModel(\n",
        "        model_type=config['model_type'],\n",
        "        random_state=config['random_state']\n",
        "    )\n",
        "    \n",
        "    # Train the model\n",
        "    print(f\"Training {config['model_type']} model...\")\n",
        "    model.fit(skate_data, plankton_data)\n",
        "    \n",
        "    # Display model performance\n",
        "    model_summary = model.get_summary()\n",
        "    if 'metrics' in model_summary:\n",
        "        metrics = model_summary['metrics']\n",
        "        print(f\"\\n📊 Model Performance:\")\n",
        "        print(f\"  Model Type: {type(model_summary['model']).__name__}\")\n",
        "        print(f\"  R² Score: {metrics['r2']:.4f}\")\n",
        "        print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
        "        print(f\"  MAE: {metrics['mae']:.4f}\")\n",
        "        print(f\"  Features Used: {len(model_summary['feature_names'])}\")\n",
        "    \n",
        "    # Create performance plots\n",
        "    if hasattr(model, 'test_data') and model.test_data is not None:\n",
        "        model.create_performance_plots(\n",
        "            model.test_data['y'],\n",
        "            model.predictions,\n",
        "            output_dir=config['output_dir']\n",
        "        )\n",
        "        print(f\"\\n📈 Model performance plots saved to: {config['output_dir']}\")\n",
        "    \n",
        "    print(f\"\\n✅ Model training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 📊 Visualizations {#visualizations}\n",
        "\n",
        "Create comprehensive visualizations of the data and analysis results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"📊 Creating Visualizations\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = Visualizer(output_dir=config['output_dir'])\n",
        "\n",
        "# Create all visualizations\n",
        "viz_results = {}\n",
        "\n",
        "print(\"Creating skate movement map...\")\n",
        "skate_map = visualizer.create_skate_movement_map(skate_data)\n",
        "viz_results['skate_map'] = skate_map\n",
        "\n",
        "if plankton_data is not None:\n",
        "    print(\"Creating plankton distribution map...\")\n",
        "    plankton_map = visualizer.create_plankton_distribution_map(plankton_data)\n",
        "    viz_results['plankton_map'] = plankton_map\n",
        "\n",
        "print(\"Creating time series plots...\")\n",
        "time_series = visualizer.create_time_series_plots(skate_data, plankton_data)\n",
        "viz_results['time_series'] = time_series\n",
        "\n",
        "print(\"Creating correlation heatmap...\")\n",
        "correlation = visualizer.create_correlation_heatmap(skate_data, plankton_data)\n",
        "viz_results['correlation'] = correlation\n",
        "\n",
        "print(\"Creating interactive dashboard...\")\n",
        "dashboard = visualizer.create_dashboard(skate_data, plankton_data, model)\n",
        "viz_results['dashboard'] = dashboard\n",
        "\n",
        "print(\"Creating summary report...\")\n",
        "summary_report = visualizer.create_summary_report(skate_data, plankton_data, model)\n",
        "viz_results['summary_report'] = summary_report\n",
        "\n",
        "print(\"Creating enhanced skate map with PNG overlays...\")\n",
        "enhanced_map = visualizer.create_enhanced_skate_map_with_png(skate_data)\n",
        "viz_results['enhanced_map'] = enhanced_map\n",
        "\n",
        "print(\"Creating PNG dashboard...\")\n",
        "png_dashboard = visualizer.create_png_dashboard(skate_data, plankton_data)\n",
        "viz_results['png_dashboard'] = png_dashboard\n",
        "\n",
        "print(\"Creating final integrated map...\")\n",
        "final_map = visualizer.create_integrated_final_map(skate_data, plankton_data)\n",
        "viz_results['final_integrated_map'] = final_map\n",
        "\n",
        "print(f\"\\n✅ All visualizations created and saved to: {config['output_dir']}\")\n",
        "print(\"\\n📋 Generated visualizations:\")\n",
        "for viz_name, viz_path in viz_results.items():\n",
        "    if viz_path:\n",
        "        print(f\"  📊 {viz_name}: {os.path.basename(viz_path)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 📋 Results and Analysis {#results}\n",
        "\n",
        "Generate a comprehensive analysis report and summary of all results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"📋 Generating Analysis Report\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Generate comprehensive report\n",
        "report_path = os.path.join(config['output_dir'], 'analysis_report.txt')\n",
        "\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"SKATE-PLANKTON ECOSYSTEM ANALYSIS REPORT\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "    \n",
        "    # Skate data summary\n",
        "    if skate_data is not None:\n",
        "        f.write(\"SKATE DATA SUMMARY:\\n\")\n",
        "        f.write(f\"  Total Records: {len(skate_data):,}\\n\")\n",
        "        f.write(f\"  Individual Skates: {skate_data['individual'].nunique()}\\n\")\n",
        "        f.write(f\"  Date Range: {skate_data['date'].min()} to {skate_data['date'].max()}\\n\")\n",
        "        f.write(f\"  Geographic Range: Lat {skate_data['latitude'].min():.2f} to {skate_data['latitude'].max():.2f}, \")\n",
        "        f.write(f\"Lon {skate_data['longitude'].min():.2f} to {skate_data['longitude'].max():.2f}\\n\\n\")\n",
        "    \n",
        "    # Plankton data summary\n",
        "    if plankton_data is not None:\n",
        "        f.write(\"PLANKTON DATA SUMMARY:\\n\")\n",
        "        f.write(f\"  Total Records: {len(plankton_data):,}\\n\")\n",
        "        f.write(f\"  Variables: {len(plankton_data.columns)}\\n\")\n",
        "        f.write(f\"  Geographic Coverage: Lat {plankton_data['latitude'].min():.2f} to {plankton_data['latitude'].max():.2f}, \")\n",
        "        f.write(f\"Lon {plankton_data['longitude'].min():.2f} to {plankton_data['longitude'].max():.2f}\\n\\n\")\n",
        "    \n",
        "    # Elasmobranch data summary\n",
        "    if elasmobranch_data is not None:\n",
        "        f.write(\"ELASMOBRANCH DATA SUMMARY:\\n\")\n",
        "        f.write(f\"  Total Records: {len(elasmobranch_data):,}\\n\")\n",
        "        f.write(f\"  Species: {elasmobranch_data['species'].nunique() if 'species' in elasmobranch_data.columns else 'N/A'}\\n\\n\")\n",
        "    \n",
        "    # Model performance\n",
        "    if model is not None:\n",
        "        model_summary = model.get_summary()\n",
        "        if 'metrics' in model_summary:\n",
        "            metrics = model_summary['metrics']\n",
        "            f.write(\"MODEL PERFORMANCE:\\n\")\n",
        "            f.write(f\"  Model Type: {type(model_summary['model']).__name__}\\n\")\n",
        "            f.write(f\"  R² Score: {metrics['r2']:.4f}\\n\")\n",
        "            f.write(f\"  RMSE: {metrics['rmse']:.4f}\\n\")\n",
        "            f.write(f\"  MAE: {metrics['mae']:.4f}\\n\")\n",
        "            f.write(f\"  Features Used: {len(model_summary['feature_names'])}\\n\\n\")\n",
        "    \n",
        "    # Output files\n",
        "    f.write(\"OUTPUT FILES:\\n\")\n",
        "    f.write(\"  Data Files:\\n\")\n",
        "    f.write(\"    - skate_processed.csv\\n\")\n",
        "    if plankton_data is not None:\n",
        "        f.write(\"    - plankton_processed.csv\\n\")\n",
        "    f.write(\"  Visualizations:\\n\")\n",
        "    for viz_name, viz_path in viz_results.items():\n",
        "        if viz_path:\n",
        "            f.write(f\"    - {os.path.basename(viz_path)}\\n\")\n",
        "\n",
        "print(f\"✅ Analysis report saved to: {report_path}\")\n",
        "\n",
        "# Display the report content\n",
        "print(\"\\n📄 Analysis Report Content:\")\n",
        "print(\"-\" * 40)\n",
        "with open(report_path, 'r') as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🎯 Final Results\n",
        "\n",
        "Display the final results and next steps:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🎯 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"📁 Output directory: {config['output_dir']}\")\n",
        "print(f\"📊 Skate records processed: {len(skate_data):,}\" if skate_data is not None else \"📊 Skate records: N/A\")\n",
        "plankton_count = len(plankton_data) if plankton_data is not None else 'N/A'\n",
        "elasmobranch_count = len(elasmobranch_data) if elasmobranch_data is not None else 'N/A'\n",
        "print(f\"🦐 Plankton records processed: {plankton_count:,}\" if isinstance(plankton_count, int) else f\"🦐 Plankton records processed: {plankton_count}\")\n",
        "print(f\"🦈 Elasmobranch records processed: {elasmobranch_count:,}\" if isinstance(elasmobranch_count, int) else f\"🦈 Elasmobranch records processed: {elasmobranch_count}\")\n",
        "\n",
        "if model is not None and hasattr(model, 'metrics'):\n",
        "    print(f\"🤖 Model R² score: {model.metrics['r2']:.4f}\")\n",
        "\n",
        "print(\"\\n📋 Generated Files:\")\n",
        "print(\"  🗺️ Interactive maps and dashboards\")\n",
        "print(\"  📈 Time series and correlation plots\")\n",
        "print(\"  📊 Model performance visualizations\")\n",
        "print(\"  📄 Comprehensive analysis report\")\n",
        "\n",
        "print(\"\\n🔍 Next Steps:\")\n",
        "print(\"  1. Review the generated visualizations in the output directory\")\n",
        "print(\"  2. Open the HTML files in a web browser for interactive exploration\")\n",
        "print(\"  3. Analyze the model performance and consider parameter tuning\")\n",
        "print(\"  4. Use the processed data for further analysis or modeling\")\n",
        "\n",
        "print(f\"\\n⏱️ Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 📚 Additional Information\n",
        "\n",
        "### 🔗 Useful Links\n",
        "- [BlueCloud VLab](https://vlab.blue-cloud.org/)\n",
        "- [DIVAnd.jl Documentation](https://github.com/gher-ulg/DIVAnd.jl)\n",
        "- [EcoTaxa Platform](https://ecotaxa.obs-vlfr.fr/)\n",
        "\n",
        "### 📖 Data Sources\n",
        "- **Skate Data**: Individual tracking data from tagged skates\n",
        "- **Plankton Data**: NetCDF files from BlueCloud VLab or sample data\n",
        "- **Elasmobranch Data**: Fisheries capture data from FAO\n",
        "\n",
        "### 🛠️ Technical Details\n",
        "- **Model Types**: Random Forest, Linear Regression, Gradient Boosting\n",
        "- **Visualization**: Interactive maps using Folium and Plotly\n",
        "- **Data Processing**: Pandas for data manipulation, NumPy for numerical operations\n",
        "\n",
        "---\n",
        "\n",
        "*This notebook was generated as part of the BlueCloud Hackathon 2025 project.*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
